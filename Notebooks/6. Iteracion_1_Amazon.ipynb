{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-SSaV-bRZZl"
   },
   "source": [
    "# Paso 1: Importar Librerías de Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K4mFYevMKu6y"
   },
   "outputs": [],
   "source": [
    "pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "47ItRxlORZ9i"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from surprise import SVD, Reader, Dataset, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "209f_YHQRaCi"
   },
   "source": [
    "# Paso 2: Lectura del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown '1ChzYRhSgS7ufpUR5qTGF1jIoNt5lM5Rx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vIFqmMIRaIc",
    "outputId": "21bac72d-0298-41f1-cabe-fabb2f840b85"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-1f8e3361d82a>:2: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/content/drive/MyDrive/EspecializacionA&DS/Monografia/2doSemestre/DataFinal_Amazon.csv')  # Descomenta y proporciona la ruta si estás cargando un archivo CSV\n"
     ]
    }
   ],
   "source": [
    "# Suponiendo que tu DataFrame se llama df\n",
    "df = pd.read_csv('DataFinal_Amazon.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIdqast7RaNy"
   },
   "source": [
    "# Paso 3: Reducción de Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tOpHk3bJRaTB"
   },
   "outputs": [],
   "source": [
    "# Tomar una muestra del 30% del dataset, si es necesario\n",
    "df = df.sample(frac=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFO-xgOlRaYS"
   },
   "source": [
    "# Paso 4: Ingeniería de Características (Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pqazuy7eRada",
    "outputId": "bfb25199-b7a6-4590-f566-cf7e33dece26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        reviewDate  year  month  day  weekday\n",
      "168877  2017-10-23  2017     10   23        0\n",
      "4652188 2018-07-09  2018      7    9        0\n",
      "799784  2016-03-03  2016      3    3        3\n",
      "1025869 2017-01-10  2017      1   10        1\n",
      "2337820 2015-06-08  2015      6    8        0\n"
     ]
    }
   ],
   "source": [
    "# Convertir 'reviewDate' a formato datetime\n",
    "df['reviewDate'] = pd.to_datetime(df['reviewDate'])\n",
    "\n",
    "# Crear nuevas variables temporales\n",
    "df['year'] = df['reviewDate'].dt.year\n",
    "df['month'] = df['reviewDate'].dt.month\n",
    "df['day'] = df['reviewDate'].dt.day\n",
    "df['weekday'] = df['reviewDate'].dt.weekday\n",
    "\n",
    "print(df[['reviewDate', 'year', 'month', 'day', 'weekday']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOaaFbPYRaiy"
   },
   "source": [
    "# Paso 5: Creación de Características\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oeSU0QXlRaob"
   },
   "outputs": [],
   "source": [
    "df['reviewText_length'] = df['reviewText'].apply(lambda x: len(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QtILgaERaty"
   },
   "source": [
    "# Paso 6: Limpieza/Transformación de Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yBhdLFP8Raza"
   },
   "outputs": [],
   "source": [
    "# Eliminemos posibles duplicados:\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3SQdThwSEvz"
   },
   "source": [
    "# Paso 10: Transformación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "znsoZS7uSE0r",
    "outputId": "55694f3a-e596-44db-c78a-8420d9b5044f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-c7b197adf89a>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['price_normalized'] = (df['price'] - df['price'].mean()) / df['price'].std()\n"
     ]
    }
   ],
   "source": [
    "# Normalizar la columna de precios si es necesario:\n",
    "df['price_normalized'] = (df['price'] - df['price'].mean()) / df['price'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lMsQcyyS2NS"
   },
   "source": [
    "# Modelo de Filtrado Colaborativo usando Embedding con Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XXM_JoQfJrAb"
   },
   "outputs": [],
   "source": [
    "#df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3oQAn6BZT8ZB"
   },
   "outputs": [],
   "source": [
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22AEmdhqU9vC",
    "outputId": "6e48ec98-36e5-4ba3-ca5d-264e72eff682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       reviewerID  reviewerID_encoded        asin  asin_encoded\n",
      "0  A1BB77SEBQT8VX              121313  B00007GDFV            39\n",
      "1  A1BB77SEBQT8VX              121313  B00007GDFV            39\n",
      "2   AHWOW7D1ABO9C             1265535  B00007GDFV            39\n",
      "3   AHWOW7D1ABO9C             1265535  B00007GDFV            39\n",
      "4   AKS3GULZE0HFC             1296109  B00007GDFV            39\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Crear un LabelEncoder para cada columna\n",
    "reviewerID_encoder = LabelEncoder()\n",
    "asin_encoder = LabelEncoder()\n",
    "\n",
    "# Ajustar y transformar las columnas\n",
    "data['reviewerID_encoded'] = reviewerID_encoder.fit_transform(data['reviewerID'])\n",
    "data['asin_encoded'] = asin_encoder.fit_transform(data['asin'])\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame para verificar\n",
    "print(data[['reviewerID', 'reviewerID_encoded', 'asin', 'asin_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYTPsSlgKCQm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, Dot, Flatten, Dense\n",
    "\n",
    "# Número de usuarios únicos y número de ítems únicos\n",
    "n_users = len(np.unique(data['reviewerID_encoded']))\n",
    "n_items = len(np.unique(data['asin_encoded']))\n",
    "\n",
    "# Dimensiones del embedding\n",
    "embedding_dim = 10\n",
    "\n",
    "# Entradas\n",
    "user_input = Input(shape=(1,))\n",
    "item_input = Input(shape=(1,))\n",
    "\n",
    "# Embeddings\n",
    "user_embedding = Embedding(n_users, embedding_dim)(user_input)\n",
    "item_embedding = Embedding(n_items, embedding_dim)(item_input)\n",
    "\n",
    "# Producto punto para predecir la valoración/rating\n",
    "merged = Dot(axes=2)([user_embedding, item_embedding])\n",
    "merged = Flatten()(merged)\n",
    "\n",
    "# Modelo\n",
    "model = Model(inputs=[user_input, item_input], outputs=merged)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZN3t1PGSYEzR"
   },
   "source": [
    "verbose=0: No muestra ninguna barra de progreso ni métricas.\n",
    "\n",
    "verbose=1: Muestra una barra de progreso y actualiza las métricas después de cada lote.\n",
    "\n",
    "verbose=2: Muestra las métricas después de cada época, pero no muestra la barra de progreso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_jc_YdXVohh",
    "outputId": "41dc9a86-6a4a-47b3-c9e6-1217f2ad2ebf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1173/1173 [==============================] - 199s 169ms/step - loss: 19.4372 - mae: 4.2510\n",
      "Epoch 2/3\n",
      "1173/1173 [==============================] - 198s 169ms/step - loss: 18.6747 - mae: 4.1410\n",
      "Epoch 3/3\n",
      "1173/1173 [==============================] - 200s 171ms/step - loss: 17.1693 - mae: 3.9141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f805d9a1a50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "user_ids = data['reviewerID_encoded'].values\n",
    "item_ids = data['asin_encoded'].values\n",
    "ratings = data['overall'].values\n",
    "model.fit([user_ids, item_ids], ratings, epochs=3, batch_size=4096, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xk4lwi1iTp_6",
    "outputId": "17210bc8-5430-4950-86c9-5512ea62acbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150018/150018 [==============================] - 154s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict([user_ids, item_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sq3us00TTwSi",
    "outputId": "ce28c09f-92a6-478d-e402-3e0f7a1d47cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 15.9169\n",
      "RMSE: 3.9896\n",
      "MAE: 3.7271\n",
      "MAPE: 86.76%\n"
     ]
    }
   ],
   "source": [
    "# MSE\n",
    "mse = mean_squared_error(ratings, predictions)\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "\n",
    "# RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# MAE\n",
    "mae = mean_absolute_error(ratings, predictions)\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "# MAPE (Mean Absolute Percentage Error)\n",
    "mape = np.mean(np.abs((ratings - predictions.flatten()) / ratings)) * 100\n",
    "print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JejE6biMKCWG",
    "outputId": "24104b4a-08c0-4b16-abd3-0abad52cc2e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2345/2345 [==============================] - 391s 166ms/step - loss: 14.1258 - mae: 3.4392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f805ef5c1f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "user_ids = data['reviewerID_encoded'].values\n",
    "item_ids = data['asin_encoded'].values\n",
    "ratings = data['overall'].values\n",
    "model.fit([user_ids, item_ids], ratings, epochs=1, batch_size=2048, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d40FhQmtKCYn",
    "outputId": "7070cdbf-1796-4417-961c-37b1b04941ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150018/150018 [==============================] - 154s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "predictions = model.predict([user_ids, item_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBLU7SD_KCa-",
    "outputId": "a4159c55-04c8-4572-a09d-12b3e372a038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 12.6531\n",
      "RMSE: 3.5571\n",
      "MAE: 3.1998\n",
      "MAPE: 73.87%\n"
     ]
    }
   ],
   "source": [
    "# MSE\n",
    "mse = mean_squared_error(ratings, predictions)\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "\n",
    "# RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# MAE\n",
    "mae = mean_absolute_error(ratings, predictions)\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "# MAPE (Mean Absolute Percentage Error)\n",
    "mape = np.mean(np.abs((ratings - predictions.flatten()) / ratings)) * 100\n",
    "print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3n02-vPg5wh"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Crear los arrays con los datos\n",
    "user_ids = data['reviewerID_encoded'].values\n",
    "item_ids = data['asin_encoded'].values\n",
    "ratings = data['overall'].values\n",
    "\n",
    "# Dividir en train y test\n",
    "(user_ids_train, user_ids_test,\n",
    " item_ids_train, item_ids_test,\n",
    " ratings_train, ratings_test) = train_test_split(user_ids, item_ids, ratings, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jOiSfVMfg5tw",
    "outputId": "8ed08667-3b3d-44fe-de5b-d3e1b632fb71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1641/1641 [==============================] - 285s 174ms/step - loss: 11.1945 - mae: 2.9552\n",
      "Epoch 2/5\n",
      "1641/1641 [==============================] - 282s 172ms/step - loss: 9.0798 - mae: 2.5762\n",
      "Epoch 3/5\n",
      "1641/1641 [==============================] - 280s 171ms/step - loss: 7.1838 - mae: 2.2069\n",
      "Epoch 4/5\n",
      "1641/1641 [==============================] - 279s 170ms/step - loss: 5.6018 - mae: 1.8735\n",
      "Epoch 5/5\n",
      "1641/1641 [==============================] - 280s 171ms/step - loss: 4.3327 - mae: 1.5843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f805ef320b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar el modelo con el conjunto de entrenamiento\n",
    "model.fit([user_ids_train, item_ids_train], ratings_train, epochs=5, batch_size=2048, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SMJd_nt7g5h4",
    "outputId": "38b9edc9-d428-4719-d8f6-7da1f6d94ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 1s 2ms/step - loss: 7.0447 - mae: 2.1847\n",
      "Test Loss: 7.0447\n",
      "Test MAE: 2.1847\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo con el conjunto de prueba (opcional)\n",
    "loss, mae = model.evaluate([user_ids_test, item_ids_test], ratings_test, batch_size=2048)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test MAE: {mae:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-mutQWdqMDO",
    "outputId": "81092e4e-3c9e-4df3-a907-c3aa305b6f65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45006/45006 [==============================] - 48s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict([user_ids_test, item_ids_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "USnKRkm0KCdW",
    "outputId": "297fe6a6-b0fc-4bff-993f-05cdb0afd8ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 7.0447\n",
      "RMSE: 2.6542\n",
      "MAE: 2.1847\n",
      "MAPE: 52.60%\n"
     ]
    }
   ],
   "source": [
    "# MSE\n",
    "mse = mean_squared_error(ratings_test, predictions)\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "\n",
    "# RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# MAE\n",
    "mae = mean_absolute_error(ratings_test, predictions)\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "# MAPE (Mean Absolute Percentage Error)\n",
    "mape = np.mean(np.abs((ratings_test - predictions.flatten()) / ratings_test)) * 100\n",
    "print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxZN3FMBKeKK"
   },
   "source": [
    "# Modelo de Filtrado Colaborativo usando SVD\n",
    "\n",
    "Utilizaremos SVD para hacer recomendaciones basadas en interacciones pasadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V8EsHgJSOI-8",
    "outputId": "815adbb5-c2d6-495f-eb61-0d221398f007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1267\n",
      "SVD - RMSE: 1.1266590735004887, MSE: 1.2693606679009797, MAE: 0.8692695424111369, MAPE: 36.112821495553185\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD, Reader, Dataset, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Leer y procesar datos\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(df[['reviewerID', 'asin', 'overall']], reader)\n",
    "\n",
    "# Dividir el dataset\n",
    "trainset, testset = train_test_split(data, test_size=0.3, random_state=10)\n",
    "\n",
    "# Entrenar el modelo SVD\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "predictions_svd = svd.test(testset)\n",
    "\n",
    "# Función para calcular el Mean Absolute Percentage Error (MAPE)\n",
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Evaluar el modelo\n",
    "rmse_svd = accuracy.rmse(predictions_svd, verbose=True)\n",
    "mse_svd = mean_squared_error([pred.r_ui for pred in predictions_svd], [pred.est for pred in predictions_svd])\n",
    "mae_svd = mean_absolute_error([pred.r_ui for pred in predictions_svd], [pred.est for pred in predictions_svd])\n",
    "mape_svd = mape([pred.r_ui for pred in predictions_svd], [pred.est for pred in predictions_svd])\n",
    "\n",
    "print(f\"SVD - RMSE: {rmse_svd}, MSE: {mse_svd}, MAE: {mae_svd}, MAPE: {mape_svd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTOAZeGrujrU"
   },
   "source": [
    "# Modelo de Filtrado Colaborativo usando Embedding y Red Neuronal Multicapa con Keras:\n",
    "\n",
    "Otra enfoque popular para filtrado colaborativo es utilizar redes neuronales multicapa, que esencialmente aprenden características no lineales de los datos. Vamos a construir un modelo que fusiona los embeddings de usuarios y artículos (por ejemplo, películas) en una red neuronal densa.\n",
    "\n",
    "Este enfoque, que combina embeddings y redes neuronales multicapa, puede capturar interacciones más complejas y no lineales entre usuarios y artículos. Sin embargo, es crucial prestar atención al sobreajuste y asegurarse de que el modelo no esté simplemente memorizando los datos. Por lo tanto, es recomendable emplear técnicas de regularización, ajustar hiperparámetros y validar el rendimiento con un conjunto de datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zVRB5utBuqzB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "\n",
    "# Convertir reviewerID y asin a índices numéricos secuenciales\n",
    "df['user_id'] = df['reviewerID'].astype('category').cat.codes.values\n",
    "df['item_id'] = df['asin'].astype('category').cat.codes.values\n",
    "\n",
    "# Número de usuarios e ítems\n",
    "n_users = df['user_id'].nunique()\n",
    "n_items = df['item_id'].nunique()\n",
    "\n",
    "# Hiperparámetros\n",
    "n_latent_factors = 50  # Número de factores latentes\n",
    "hidden_units = [128, 64]  # Unidades en las capas ocultas\n",
    "dropout_rate = 0.2\n",
    "\n",
    "# Arquitectura del modelo\n",
    "user_input = Input(shape=[1], name='user_input')\n",
    "item_input = Input(shape=[1], name='item_input')\n",
    "user_embedding = Embedding(n_users, n_latent_factors, name='user_embedding')(user_input)\n",
    "item_embedding = Embedding(n_items, n_latent_factors, name='item_embedding')(item_input)\n",
    "user_vec = Flatten(name='flatten_users')(user_embedding)\n",
    "item_vec = Flatten(name='flatten_items')(item_embedding)\n",
    "concat = Concatenate()([user_vec, item_vec])\n",
    "dense = concat\n",
    "for units in hidden_units:\n",
    "    dense = Dense(units, activation='relu')(dense)\n",
    "    dense = Dropout(dropout_rate)(dense)\n",
    "output = Dense(1)(dense)\n",
    "model = Model(inputs=[user_input, item_input], outputs=output)\n",
    "model.compile(optimizer=Adam(0.001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XJfWiirYxHwk",
    "outputId": "f8872da4-c9b0-44f4-feba-32cbf5f7fe4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "557/557 [==============================] - 27s 38ms/step - loss: 2.8788 - val_loss: 1.3066\n",
      "Epoch 2/5\n",
      "557/557 [==============================] - 9s 16ms/step - loss: 1.2273 - val_loss: 1.3545\n",
      "Epoch 3/5\n",
      "557/557 [==============================] - 9s 15ms/step - loss: 0.8625 - val_loss: 1.4520\n",
      "Epoch 4/5\n",
      "557/557 [==============================] - 9s 16ms/step - loss: 0.6888 - val_loss: 1.4685\n",
      "Epoch 5/5\n",
      "557/557 [==============================] - 8s 15ms/step - loss: 0.5924 - val_loss: 1.5090\n",
      "8909/8909 [==============================] - 12s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "user_data = df['user_id'].values\n",
    "item_data = df['item_id'].values\n",
    "rating_data = df['overall'].values\n",
    "\n",
    "# Usando validation_split, divide los datos\n",
    "train_size = int(0.8 * len(user_data))\n",
    "user_data_train, user_data_val = user_data[:train_size], user_data[train_size:]\n",
    "item_data_train, item_data_val = item_data[:train_size], item_data[train_size:]\n",
    "y_true = rating_data[train_size:]\n",
    "\n",
    "history = model.fit([user_data_train, item_data_train], rating_data[:train_size],\n",
    "                    epochs=5, validation_data=([user_data_val, item_data_val], y_true),\n",
    "                    batch_size=2048, verbose=1)\n",
    "\n",
    "# Predicciones\n",
    "predictions = model.predict([user_data_val, item_data_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1BY-Sd0xJtc",
    "outputId": "f3e653ed-9d49-4371-c0d7-04ba8793e1c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.508964377056769\n",
      "RMSE: 1.2283991114685686\n",
      "MAE: 0.9115688753774837\n",
      "MAPE: 40.61646684475661%\n"
     ]
    }
   ],
   "source": [
    "# MSE y RMSE\n",
    "mse = mean_squared_error(y_true, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# MAE\n",
    "mae = mean_absolute_error(y_true, predictions)\n",
    "\n",
    "# MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_idx = y_true != 0  # Para evitar divisiones por cero\n",
    "    return np.mean(np.abs((y_true[non_zero_idx] - y_pred[non_zero_idx]) / y_true[non_zero_idx])) * 100\n",
    "\n",
    "def compute_mape_by_batch(y_true, predictions, batch_size=50000):\n",
    "    mape_sum = 0\n",
    "    num_batches = int(np.ceil(len(y_true) / batch_size))\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "\n",
    "        batch_y_true = y_true[start_idx:end_idx]\n",
    "        batch_predictions = predictions[start_idx:end_idx]\n",
    "\n",
    "        mape_sum += mean_absolute_percentage_error(batch_y_true, batch_predictions)\n",
    "\n",
    "    return mape_sum / num_batches\n",
    "\n",
    "# Luego llamas a la función\n",
    "mape = compute_mape_by_batch(y_true, predictions)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MAPE: {mape}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YopA3D2Sw8AO"
   },
   "source": [
    "Estas métricas te ayudarán a tener una mejor idea del desempeño de tu modelo. Por ejemplo:\n",
    "\n",
    "MSE y RMSE son útiles cuando quieres penalizar grandes errores.\n",
    "\n",
    "MAE te da una idea del error medio sin considerar la dirección del error.\n",
    "\n",
    "MAPE es útil cuando quieres representar el error en términos porcentuales.\n",
    "\n",
    "Para una evaluación completa, es recomendable utilizar un conjunto de validación aparte (es decir, no solo depender del validation_split). Esto asegura que estás evaluando el desempeño en datos que el modelo nunca ha visto durante el entrenamiento."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
