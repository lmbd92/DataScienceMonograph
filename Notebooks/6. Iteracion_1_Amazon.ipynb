{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 1: Importar Librerías de Python\n"
      ],
      "metadata": {
        "id": "V-SSaV-bRZZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install scikit-surprise"
      ],
      "metadata": {
        "id": "K4mFYevMKu6y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from surprise import SVD, Reader, Dataset, accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "47ItRxlORZ9i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8bHcBRlQYY4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "791368eb-72f1-4632-b5e7-8d711ad71189"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 2: Lectura del Dataset"
      ],
      "metadata": {
        "id": "209f_YHQRaCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Suponiendo que tu DataFrame se llama df\n",
        "df = pd.read_csv('/content/drive/MyDrive/EspecializacionA&DS/Monografia/2doSemestre/DataFinal_Amazon.csv')  # Descomenta y proporciona la ruta si estás cargando un archivo CSV"
      ],
      "metadata": {
        "id": "9vIFqmMIRaIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21bac72d-0298-41f1-cabe-fabb2f840b85"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-1f8e3361d82a>:2: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/drive/MyDrive/EspecializacionA&DS/Monografia/2doSemestre/DataFinal_Amazon.csv')  # Descomenta y proporciona la ruta si estás cargando un archivo CSV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 3: Reducción de Datos\n"
      ],
      "metadata": {
        "id": "bIdqast7RaNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tomar una muestra del 10% del dataset, si es necesario\n",
        "df = df.sample(frac=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "tOpHk3bJRaTB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 4: Ingeniería de Características (Feature Engineering)"
      ],
      "metadata": {
        "id": "dFO-xgOlRaYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'reviewDate' to datetime format\n",
        "df['reviewDate'] = pd.to_datetime(df['reviewDate'])\n",
        "\n",
        "# Create new temporal columns\n",
        "df['year'] = df['reviewDate'].dt.year\n",
        "df['month'] = df['reviewDate'].dt.month\n",
        "df['day'] = df['reviewDate'].dt.day\n",
        "df['weekday'] = df['reviewDate'].dt.weekday\n",
        "\n",
        "print(df[['reviewDate', 'year', 'month', 'day', 'weekday']].head())"
      ],
      "metadata": {
        "id": "pqazuy7eRada",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb25199-b7a6-4590-f566-cf7e33dece26"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        reviewDate  year  month  day  weekday\n",
            "168877  2017-10-23  2017     10   23        0\n",
            "4652188 2018-07-09  2018      7    9        0\n",
            "799784  2016-03-03  2016      3    3        3\n",
            "1025869 2017-01-10  2017      1   10        1\n",
            "2337820 2015-06-08  2015      6    8        0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 5: Creación de Características\n"
      ],
      "metadata": {
        "id": "XOaaFbPYRaiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#A modo de ejemplo, supongamos que deseamos conocer la longitud del texto de revisión:\n",
        "df['reviewText_length'] = df['reviewText'].apply(lambda x: len(str(x)))"
      ],
      "metadata": {
        "id": "oeSU0QXlRaob"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 6: Limpieza/Transformación de Datos\n"
      ],
      "metadata": {
        "id": "3QtILgaERaty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminemos posibles duplicados:\n",
        "df = df.drop_duplicates()"
      ],
      "metadata": {
        "id": "yBhdLFP8Raza"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 10: Transformación de Datos"
      ],
      "metadata": {
        "id": "u3SQdThwSEvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar la columna de precios si es necesario:\n",
        "df['price_normalized'] = (df['price'] - df['price'].mean()) / df['price'].std()"
      ],
      "metadata": {
        "id": "znsoZS7uSE0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55694f3a-e596-44db-c78a-8420d9b5044f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-c7b197adf89a>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['price_normalized'] = (df['price'] - df['price'].mean()) / df['price'].std()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo 1 de Prueba\n",
        "\n",
        "Modelo de filtrado colaborativo utilizando Keras:"
      ],
      "metadata": {
        "id": "5lMsQcyyS2NS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df.head(3)"
      ],
      "metadata": {
        "id": "XXM_JoQfJrAb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df"
      ],
      "metadata": {
        "id": "3oQAn6BZT8ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Crear un LabelEncoder para cada columna\n",
        "reviewerID_encoder = LabelEncoder()\n",
        "asin_encoder = LabelEncoder()\n",
        "\n",
        "# Ajustar y transformar las columnas\n",
        "data['reviewerID_encoded'] = reviewerID_encoder.fit_transform(data['reviewerID'])\n",
        "data['asin_encoded'] = asin_encoder.fit_transform(data['asin'])\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame para verificar\n",
        "print(data[['reviewerID', 'reviewerID_encoded', 'asin', 'asin_encoded']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22AEmdhqU9vC",
        "outputId": "6e48ec98-36e5-4ba3-ca5d-264e72eff682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       reviewerID  reviewerID_encoded        asin  asin_encoded\n",
            "0  A1BB77SEBQT8VX              121313  B00007GDFV            39\n",
            "1  A1BB77SEBQT8VX              121313  B00007GDFV            39\n",
            "2   AHWOW7D1ABO9C             1265535  B00007GDFV            39\n",
            "3   AHWOW7D1ABO9C             1265535  B00007GDFV            39\n",
            "4   AKS3GULZE0HFC             1296109  B00007GDFV            39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Embedding, Input, Dot, Flatten, Dense\n",
        "\n",
        "# Número de usuarios únicos y número de ítems únicos\n",
        "n_users = len(np.unique(data['reviewerID_encoded']))\n",
        "n_items = len(np.unique(data['asin_encoded']))\n",
        "\n",
        "# Dimensiones del embedding\n",
        "embedding_dim = 10\n",
        "\n",
        "# Entradas\n",
        "user_input = Input(shape=(1,))\n",
        "item_input = Input(shape=(1,))\n",
        "\n",
        "# Embeddings\n",
        "user_embedding = Embedding(n_users, embedding_dim)(user_input)\n",
        "item_embedding = Embedding(n_items, embedding_dim)(item_input)\n",
        "\n",
        "# Producto punto para predecir la valoración/rating\n",
        "merged = Dot(axes=2)([user_embedding, item_embedding])\n",
        "merged = Flatten()(merged)\n",
        "\n",
        "# Modelo\n",
        "model = Model(inputs=[user_input, item_input], outputs=merged)\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ],
      "metadata": {
        "id": "fYTPsSlgKCQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "verbose=0: No muestra ninguna barra de progreso ni métricas.\n",
        "\n",
        "verbose=1: Muestra una barra de progreso y actualiza las métricas después de cada lote.\n",
        "\n",
        "verbose=2: Muestra las métricas después de cada época, pero no muestra la barra de progreso."
      ],
      "metadata": {
        "id": "ZN3t1PGSYEzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "user_ids = data['reviewerID_encoded'].values\n",
        "item_ids = data['asin_encoded'].values\n",
        "ratings = data['overall'].values\n",
        "model.fit([user_ids, item_ids], ratings, epochs=3, batch_size=4096, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_jc_YdXVohh",
        "outputId": "41dc9a86-6a4a-47b3-c9e6-1217f2ad2ebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1173/1173 [==============================] - 199s 169ms/step - loss: 19.4372 - mae: 4.2510\n",
            "Epoch 2/3\n",
            "1173/1173 [==============================] - 198s 169ms/step - loss: 18.6747 - mae: 4.1410\n",
            "Epoch 3/3\n",
            "1173/1173 [==============================] - 200s 171ms/step - loss: 17.1693 - mae: 3.9141\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f805d9a1a50>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predictions = model.predict([user_ids, item_ids])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk4lwi1iTp_6",
        "outputId": "17210bc8-5430-4950-86c9-5512ea62acbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150018/150018 [==============================] - 154s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MSE\n",
        "mse = mean_squared_error(ratings, predictions)\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "\n",
        "# RMSE\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "# MAE\n",
        "mae = mean_absolute_error(ratings, predictions)\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "\n",
        "# MAPE (Mean Absolute Percentage Error)\n",
        "mape = np.mean(np.abs((ratings - predictions.flatten()) / ratings)) * 100\n",
        "print(f\"MAPE: {mape:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq3us00TTwSi",
        "outputId": "ce28c09f-92a6-478d-e402-3e0f7a1d47cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 15.9169\n",
            "RMSE: 3.9896\n",
            "MAE: 3.7271\n",
            "MAPE: 86.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.aprendemachinelearning.com/sistemas-de-recomendacion/"
      ],
      "metadata": {
        "id": "U72CIb2yKCTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "user_ids = data['reviewerID_encoded'].values\n",
        "item_ids = data['asin_encoded'].values\n",
        "ratings = data['overall'].values\n",
        "model.fit([user_ids, item_ids], ratings, epochs=1, batch_size=2048, verbose=1)"
      ],
      "metadata": {
        "id": "JejE6biMKCWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24104b4a-08c0-4b16-abd3-0abad52cc2e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2345/2345 [==============================] - 391s 166ms/step - loss: 14.1258 - mae: 3.4392\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f805ef5c1f0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "predictions = model.predict([user_ids, item_ids])\n"
      ],
      "metadata": {
        "id": "d40FhQmtKCYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7070cdbf-1796-4417-961c-37b1b04941ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150018/150018 [==============================] - 154s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MSE\n",
        "mse = mean_squared_error(ratings, predictions)\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "\n",
        "# RMSE\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "# MAE\n",
        "mae = mean_absolute_error(ratings, predictions)\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "\n",
        "# MAPE (Mean Absolute Percentage Error)\n",
        "mape = np.mean(np.abs((ratings - predictions.flatten()) / ratings)) * 100\n",
        "print(f\"MAPE: {mape:.2f}%\")\n"
      ],
      "metadata": {
        "id": "zBLU7SD_KCa-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4159c55-04c8-4572-a09d-12b3e372a038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 12.6531\n",
            "RMSE: 3.5571\n",
            "MAE: 3.1998\n",
            "MAPE: 73.87%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Crear los arrays con los datos\n",
        "user_ids = data['reviewerID_encoded'].values\n",
        "item_ids = data['asin_encoded'].values\n",
        "ratings = data['overall'].values\n",
        "\n",
        "# Dividir en train y test\n",
        "(user_ids_train, user_ids_test,\n",
        " item_ids_train, item_ids_test,\n",
        " ratings_train, ratings_test) = train_test_split(user_ids, item_ids, ratings, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "J3n02-vPg5wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo con el conjunto de entrenamiento\n",
        "model.fit([user_ids_train, item_ids_train], ratings_train, epochs=5, batch_size=2048, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOiSfVMfg5tw",
        "outputId": "8ed08667-3b3d-44fe-de5b-d3e1b632fb71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1641/1641 [==============================] - 285s 174ms/step - loss: 11.1945 - mae: 2.9552\n",
            "Epoch 2/5\n",
            "1641/1641 [==============================] - 282s 172ms/step - loss: 9.0798 - mae: 2.5762\n",
            "Epoch 3/5\n",
            "1641/1641 [==============================] - 280s 171ms/step - loss: 7.1838 - mae: 2.2069\n",
            "Epoch 4/5\n",
            "1641/1641 [==============================] - 279s 170ms/step - loss: 5.6018 - mae: 1.8735\n",
            "Epoch 5/5\n",
            "1641/1641 [==============================] - 280s 171ms/step - loss: 4.3327 - mae: 1.5843\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f805ef320b0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo con el conjunto de prueba (opcional)\n",
        "loss, mae = model.evaluate([user_ids_test, item_ids_test], ratings_test, batch_size=2048)\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test MAE: {mae:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMJd_nt7g5h4",
        "outputId": "38b9edc9-d428-4719-d8f6-7da1f6d94ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "704/704 [==============================] - 1s 2ms/step - loss: 7.0447 - mae: 2.1847\n",
            "Test Loss: 7.0447\n",
            "Test MAE: 2.1847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict([user_ids_test, item_ids_test])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-mutQWdqMDO",
        "outputId": "81092e4e-3c9e-4df3-a907-c3aa305b6f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45006/45006 [==============================] - 48s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MSE\n",
        "mse = mean_squared_error(ratings_test, predictions)\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "\n",
        "# RMSE\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "# MAE\n",
        "mae = mean_absolute_error(ratings_test, predictions)\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "\n",
        "# MAPE (Mean Absolute Percentage Error)\n",
        "mape = np.mean(np.abs((ratings_test - predictions.flatten()) / ratings_test)) * 100\n",
        "print(f\"MAPE: {mape:.2f}%\")\n"
      ],
      "metadata": {
        "id": "USnKRkm0KCdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "297fe6a6-b0fc-4bff-993f-05cdb0afd8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 7.0447\n",
            "RMSE: 2.6542\n",
            "MAE: 2.1847\n",
            "MAPE: 52.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sistema de recomendación basado en filtrado colaborativo:\n",
        "\n",
        "Utilizaremos SVD para hacer recomendaciones basadas en interacciones pasadas.\n"
      ],
      "metadata": {
        "id": "mxZN3FMBKeKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import SVD, Reader, Dataset, accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# Leer y procesar datos\n",
        "reader = Reader()\n",
        "data = Dataset.load_from_df(df[['reviewerID', 'asin', 'overall']], reader)\n",
        "\n",
        "# Dividir el dataset\n",
        "trainset, testset = train_test_split(data, test_size=0.3, random_state=10)\n",
        "\n",
        "# Entrenar el modelo SVD\n",
        "svd = SVD()\n",
        "svd.fit(trainset)\n",
        "predictions_svd = svd.test(testset)\n",
        "\n",
        "# Función para calcular el Mean Absolute Percentage Error (MAPE)\n",
        "def mape(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "# Evaluar el modelo\n",
        "rmse_svd = accuracy.rmse(predictions_svd, verbose=True)\n",
        "mse_svd = mean_squared_error([pred.r_ui for pred in predictions_svd], [pred.est for pred in predictions_svd])\n",
        "mae_svd = mean_absolute_error([pred.r_ui for pred in predictions_svd], [pred.est for pred in predictions_svd])\n",
        "mape_svd = mape([pred.r_ui for pred in predictions_svd], [pred.est for pred in predictions_svd])\n",
        "\n",
        "print(f\"SVD - RMSE: {rmse_svd}, MSE: {mse_svd}, MAE: {mae_svd}, MAPE: {mape_svd}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8EsHgJSOI-8",
        "outputId": "815adbb5-c2d6-495f-eb61-0d221398f007"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 1.1267\n",
            "SVD - RMSE: 1.1266590735004887, MSE: 1.2693606679009797, MAE: 0.8692695424111369, MAPE: 36.112821495553185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de Filtrado Colaborativo usando Red Neuronal Multicapa con Keras:\n",
        "\n",
        "Otra enfoque popular para filtrado colaborativo es utilizar redes neuronales multicapa, que esencialmente aprenden características no lineales de los datos. Vamos a construir un modelo que fusiona los embeddings de usuarios y artículos (por ejemplo, películas) en una red neuronal densa.\n",
        "\n",
        "Este enfoque, que combina embeddings y redes neuronales multicapa, puede capturar interacciones más complejas y no lineales entre usuarios y artículos. Sin embargo, es crucial prestar atención al sobreajuste y asegurarse de que el modelo no esté simplemente memorizando los datos. Por lo tanto, es recomendable emplear técnicas de regularización, ajustar hiperparámetros y validar el rendimiento con un conjunto de datos de validación."
      ],
      "metadata": {
        "id": "WTOAZeGrujrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "\n",
        "# Suponiendo que el DataFrame se llama df\n",
        "df = df\n",
        "\n",
        "# Convertir reviewerID y asin a índices numéricos secuenciales\n",
        "df['user_id'] = df['reviewerID'].astype('category').cat.codes.values\n",
        "df['item_id'] = df['asin'].astype('category').cat.codes.values\n",
        "\n",
        "# Número de usuarios e ítems\n",
        "n_users = df['user_id'].nunique()\n",
        "n_items = df['item_id'].nunique()\n",
        "\n",
        "# Hiperparámetros\n",
        "n_latent_factors = 50  # Número de factores latentes\n",
        "hidden_units = [128, 64]  # Unidades en las capas ocultas\n",
        "dropout_rate = 0.2\n",
        "\n",
        "# Arquitectura del modelo\n",
        "user_input = Input(shape=[1], name='user_input')\n",
        "item_input = Input(shape=[1], name='item_input')\n",
        "user_embedding = Embedding(n_users, n_latent_factors, name='user_embedding')(user_input)\n",
        "item_embedding = Embedding(n_items, n_latent_factors, name='item_embedding')(item_input)\n",
        "user_vec = Flatten(name='flatten_users')(user_embedding)\n",
        "item_vec = Flatten(name='flatten_items')(item_embedding)\n",
        "concat = Concatenate()([user_vec, item_vec])\n",
        "dense = concat\n",
        "for units in hidden_units:\n",
        "    dense = Dense(units, activation='relu')(dense)\n",
        "    dense = Dropout(dropout_rate)(dense)\n",
        "output = Dense(1)(dense)\n",
        "model = Model(inputs=[user_input, item_input], outputs=output)\n",
        "model.compile(optimizer=Adam(0.001), loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "zVRB5utBuqzB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "user_data = df['user_id'].values\n",
        "item_data = df['item_id'].values\n",
        "rating_data = df['overall'].values\n",
        "\n",
        "# Usando validation_split, divide los datos\n",
        "train_size = int(0.8 * len(user_data))\n",
        "user_data_train, user_data_val = user_data[:train_size], user_data[train_size:]\n",
        "item_data_train, item_data_val = item_data[:train_size], item_data[train_size:]\n",
        "y_true = rating_data[train_size:]\n",
        "\n",
        "history = model.fit([user_data_train, item_data_train], rating_data[:train_size],\n",
        "                    epochs=5, validation_data=([user_data_val, item_data_val], y_true),\n",
        "                    batch_size=2048, verbose=1)\n",
        "\n",
        "# Predicciones\n",
        "predictions = model.predict([user_data_val, item_data_val])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJfWiirYxHwk",
        "outputId": "f8872da4-c9b0-44f4-feba-32cbf5f7fe4c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "557/557 [==============================] - 27s 38ms/step - loss: 2.8788 - val_loss: 1.3066\n",
            "Epoch 2/5\n",
            "557/557 [==============================] - 9s 16ms/step - loss: 1.2273 - val_loss: 1.3545\n",
            "Epoch 3/5\n",
            "557/557 [==============================] - 9s 15ms/step - loss: 0.8625 - val_loss: 1.4520\n",
            "Epoch 4/5\n",
            "557/557 [==============================] - 9s 16ms/step - loss: 0.6888 - val_loss: 1.4685\n",
            "Epoch 5/5\n",
            "557/557 [==============================] - 8s 15ms/step - loss: 0.5924 - val_loss: 1.5090\n",
            "8909/8909 [==============================] - 12s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MSE y RMSE\n",
        "mse = mean_squared_error(y_true, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# MAE\n",
        "mae = mean_absolute_error(y_true, predictions)\n",
        "\n",
        "# MAPE\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    non_zero_idx = y_true != 0  # Para evitar divisiones por cero\n",
        "    return np.mean(np.abs((y_true[non_zero_idx] - y_pred[non_zero_idx]) / y_true[non_zero_idx])) * 100\n",
        "\n",
        "def compute_mape_by_batch(y_true, predictions, batch_size=50000):\n",
        "    mape_sum = 0\n",
        "    num_batches = int(np.ceil(len(y_true) / batch_size))\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        start_idx = i * batch_size\n",
        "        end_idx = start_idx + batch_size\n",
        "\n",
        "        batch_y_true = y_true[start_idx:end_idx]\n",
        "        batch_predictions = predictions[start_idx:end_idx]\n",
        "\n",
        "        mape_sum += mean_absolute_percentage_error(batch_y_true, batch_predictions)\n",
        "\n",
        "    return mape_sum / num_batches\n",
        "\n",
        "# Luego llamas a la función\n",
        "mape = compute_mape_by_batch(y_true, predictions)\n",
        "\n",
        "print(f'MSE: {mse}')\n",
        "print(f'RMSE: {rmse}')\n",
        "print(f'MAE: {mae}')\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1BY-Sd0xJtc",
        "outputId": "f3e653ed-9d49-4371-c0d7-04ba8793e1c5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 1.508964377056769\n",
            "RMSE: 1.2283991114685686\n",
            "MAE: 0.9115688753774837\n",
            "MAPE: 40.61646684475661%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estas métricas te ayudarán a tener una mejor idea del desempeño de tu modelo. Por ejemplo:\n",
        "\n",
        "MSE y RMSE son útiles cuando quieres penalizar grandes errores.\n",
        "\n",
        "MAE te da una idea del error medio sin considerar la dirección del error.\n",
        "\n",
        "MAPE es útil cuando quieres representar el error en términos porcentuales.\n",
        "\n",
        "Para una evaluación completa, es recomendable utilizar un conjunto de validación aparte (es decir, no solo depender del validation_split). Esto asegura que estás evaluando el desempeño en datos que el modelo nunca ha visto durante el entrenamiento."
      ],
      "metadata": {
        "id": "YopA3D2Sw8AO"
      }
    }
  ]
}